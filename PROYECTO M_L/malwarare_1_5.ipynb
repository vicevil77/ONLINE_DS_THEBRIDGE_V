{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Habilita el crecimiento de memoria para todos los dispositivos GPU antes de inicializar el runtime\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Actualmente, la configuración de crecimiento de memoria solo está disponible en CUDA\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        # Si ya se ha inicializado el runtime, se producirá un error al intentar establecer el crecimiento de memoria.\n",
    "        print(e)\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # Especifica la GPU a utilizar (0 para la primera GPU)\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.9.0\n",
      "TensorFlow is running on: Windows-10-10.0.22631-SP0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import platform\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"TensorFlow is running on:\", platform.platform())\n",
    "\n",
    "# Obtén la versión de CUDA\n",
    "devices = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "#import seaborn as sns\n",
    "import os\n",
    "#from scipy.sparse import hstack\n",
    "#import funciones_ML as bt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, FeatureHasher\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, LabelEncoder, Normalizer,MaxAbsScaler\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay,classification_report,r2_score,RocCurveDisplay,confusion_matrix, accuracy_score,recall_score,f1_score,precision_score,precision_recall_fscore_support\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor, SGDClassifier, RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint,ReduceLROnPlateau,CallbackList\n",
    "from tensorflow.keras.regularizers import l2, l1, l1_l2\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, sparse_categorical_crossentropy, binary_crossentropy\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "# Ruta al archivo CSV gigante\n",
    "file_path_wsl = \"/mnt/d/Cursos/REPOSITORIOS/DATASET/malware_total/original/df_one_hot_full_ml_mm.csv\"\n",
    "file_path_w11= \"D:\\Cursos\\REPOSITORIOS\\DATASET\\malware_total\\original\\df_one_hot_full_ml_mm.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import dask.distributed\n",
    "import dask\n",
    "import cupy as cp\n",
    "from dask.distributed import LocalCluster, Client\n",
    "from distributed import Client\n",
    "import threadpoolctl\n",
    "from dask.delayed import Delayed\n",
    "from sklearn.utils import check_random_state\n",
    "import ray.data as rd\n",
    "import ray\n",
    "import ray.data\n",
    "import dask\n",
    "from dask_ml.wrappers import Incremental\n",
    "from dask_ml.decomposition import PCA\n",
    "from dask_ml.datasets import make_regression\n",
    "import vaex\n",
    "from dask.diagnostics import ProgressBar\n",
    "import tables\n",
    "import h5py\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import dask.array as da\n",
    "\n",
    "# Crear un array de Dask respaldado por CuPy\n",
    "x_gpu = da.from_array(cp.ones((10000, 10000)), chunks=(1000, 1000))\n",
    "\n",
    "# Realizar una operación de reducción en paralelo en la GPU\n",
    "sum_gpu = x_gpu.sum().compute()\n",
    "\n",
    "print(sum_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Función para simular una tarea que tarda un tiempo\n",
    "def tarea_larga(n):\n",
    "  for i in tqdm(range(n), desc=\"Procesando datos...\", unit=\"iteraciones\", total=n, leave=True):\n",
    "    time.sleep(0.1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=ray.data.read_csv(file_path_w11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column                Type\n",
       "------                ----\n",
       "                      int64\n",
       "0                     double\n",
       "1                     double\n",
       "2                     double\n",
       "3                     double\n",
       "4                     double\n",
       "5                     double\n",
       "6                     double\n",
       "proto_icmp            double\n",
       "proto_tcp             double\n",
       "proto_udp             double\n",
       "conn_state_OTH        double\n",
       "conn_state_REJ        double\n",
       "conn_state_RSTO       double\n",
       "conn_state_RSTOS0     double\n",
       "conn_state_RSTR       double\n",
       "conn_state_RSTRH      double\n",
       "conn_state_S0         double\n",
       "conn_state_S1         double\n",
       "conn_state_S2         double\n",
       "conn_state_S3         double\n",
       "conn_state_SF         double\n",
       "conn_state_SH         double\n",
       "conn_state_SHR        double\n",
       "history_Aa            double\n",
       "history_Ar            double\n",
       "history_C             double\n",
       "history_CCC           double\n",
       "history_CCCC          double\n",
       "history_D             double\n",
       "history_DAd           double\n",
       "history_DFafA         double\n",
       "history_DFr           double\n",
       "history_DT            double\n",
       "history_DTT           double\n",
       "history_D^            double\n",
       "history_D^d           double\n",
       "history_DaFfA         double\n",
       "history_Dd            double\n",
       "history_DdA           double\n",
       "history_DdAa          double\n",
       "history_DdAaFf        double\n",
       "history_DdAtaFf       double\n",
       "history_Dr            double\n",
       "history_DrF           double\n",
       "history_F             double\n",
       "history_Fa            double\n",
       "history_FaAr          double\n",
       "history_FaR           double\n",
       "history_FfA           double\n",
       "history_Ffa           double\n",
       "history_Fr            double\n",
       "history_HaADdFf       double\n",
       "history_HaDdAFTf      double\n",
       "history_HaDdAFf       double\n",
       "history_HaDdAfF       double\n",
       "history_HaDdAr        double\n",
       "history_HaDdR         double\n",
       "history_HaDdTAFf      double\n",
       "history_HaFfA         double\n",
       "history_HaR           double\n",
       "history_HafFr         double\n",
       "history_I             double\n",
       "history_R             double\n",
       "history_S             double\n",
       "history_SAD           double\n",
       "history_SI            double\n",
       "history_SaR           double\n",
       "history_SahAdDF       double\n",
       "history_SahAdDFRf     double\n",
       "history_SahAdDFf      double\n",
       "history_SahAdDrfR     double\n",
       "history_SahAdDtFf     double\n",
       "history_ShA           double\n",
       "history_ShAD          double\n",
       "history_ShADCaGcgd    double\n",
       "history_ShADCaGdfF    double\n",
       "history_ShADF         double\n",
       "history_ShADFa        double\n",
       "history_ShADFaR       double\n",
       "history_ShADFadfR     double\n",
       "history_ShADFadfRR    double\n",
       "history_ShADFar       double\n",
       "history_ShADFfR       double\n",
       "history_ShADFfa       double\n",
       "history_ShADFr        double\n",
       "history_ShADa         double\n",
       "history_ShADaCGcgdF   double\n",
       "history_ShADaCGdt     double\n",
       "history_ShADaCGdtfF   double\n",
       "history_ShADaCGr      double\n",
       "history_ShADaF        double\n",
       "history_ShADaFr       double\n",
       "history_ShADaR        double\n",
       "history_ShADacdtfF    double\n",
       "history_ShADad        double\n",
       "history_ShADadFf      double\n",
       "history_ShADadFfR     double\n",
       "history_ShADadR       double\n",
       "history_ShADadRf      double\n",
       "history_ShADadf       double\n",
       "history_ShADadfF      double\n",
       "history_ShADadfR      double\n",
       "history_ShADadfr      double\n",
       "history_ShADadfrr     double\n",
       "history_ShADadftFR    double\n",
       "history_ShADadtFf     double\n",
       "history_ShADadtRf     double\n",
       "history_ShADadtcfF    double\n",
       "history_ShADadtctfF   double\n",
       "history_ShADadtctfFR  double\n",
       "history_ShADadtfF     double\n",
       "history_ShADadttFf    double\n",
       "history_ShADadttcfF   double\n",
       "history_ShADadttfF    double\n",
       "history_ShADafF       double\n",
       "history_ShADafdtF     double\n",
       "history_ShADafr       double\n",
       "history_ShADar        double\n",
       "history_ShADarfF      double\n",
       "history_ShADdFaf      double\n",
       "history_ShADdFf       double\n",
       "history_ShADda        double\n",
       "history_ShADdaf       double\n",
       "history_ShADdafR      double\n",
       "history_ShADdattFfR   double\n",
       "history_ShADdf        double\n",
       "history_ShADdfF       double\n",
       "history_ShADdfFa      double\n",
       "history_ShADdfR       double\n",
       "history_ShADdtaFf     double\n",
       "history_ShADdtatFfR   double\n",
       "history_ShADfF        double\n",
       "history_ShADfFa       double\n",
       "history_ShADfFr       double\n",
       "history_ShADfFrr      double\n",
       "history_ShADfR        double\n",
       "history_ShADfaF       double\n",
       "history_ShADfdtFaR    double\n",
       "history_ShADfdtR      double\n",
       "history_ShADfrF       double\n",
       "history_ShADfrFr      double\n",
       "history_ShADr         double\n",
       "history_ShADrfR       double\n",
       "history_ShAF          double\n",
       "history_ShAFa         double\n",
       "history_ShAFafR       double\n",
       "history_ShAFdRfR      double\n",
       "history_ShAFdfRt      double\n",
       "history_ShAFf         double\n",
       "history_ShAFfR        double\n",
       "history_ShAFr         double\n",
       "history_ShAa          double\n",
       "history_ShAadDFR      double\n",
       "history_ShAadDFRf     double\n",
       "history_ShAadDFf      double\n",
       "history_ShAadDfF      double\n",
       "history_ShAadDr       double\n",
       "history_ShAafF        double\n",
       "history_ShAar         double\n",
       "history_ShAaw         double\n",
       "history_ShAaww        double\n",
       "history_ShAdD         double\n",
       "history_ShAdDFaf      double\n",
       "history_ShAdDFar      double\n",
       "history_ShAdDFf       double\n",
       "history_ShAdDFfR      double\n",
       "history_ShAdDR        double\n",
       "history_ShAdDTafF     double\n",
       "history_ShAdDa        double\n",
       "history_ShAdDaF       double\n",
       "history_ShAdDaFR      double\n",
       "history_ShAdDaFRR     double\n",
       "history_ShAdDaFRRRf   double\n",
       "history_ShAdDaFRRf    double\n",
       "history_ShAdDaFRRfR   double\n",
       "history_ShAdDaFRf     double\n",
       "history_ShAdDaFRfR    double\n",
       "history_ShAdDaFRfRR   double\n",
       "history_ShAdDaFRr     double\n",
       "history_ShAdDaFT      double\n",
       "history_ShAdDaFTf     double\n",
       "history_ShAdDaFf      double\n",
       "history_ShAdDaFfR     double\n",
       "history_ShAdDaFfRR    double\n",
       "history_ShAdDaFfr     double\n",
       "history_ShAdDaFr      double\n",
       "history_ShAdDaFrR     double\n",
       "history_ShAdDaR       double\n",
       "history_ShAdDaRR      double\n",
       "history_ShAdDaRRR     double\n",
       "history_ShAdDaRr      double\n",
       "history_ShAdDaT       double\n",
       "history_ShAdDaTF      double\n",
       "history_ShAdDaTFR     double\n",
       "history_ShAdDaTFRf    double\n",
       "history_ShAdDaTFf     double\n",
       "history_ShAdDaTFfR    double\n",
       "history_ShAdDaTR      double\n",
       "history_ShAdDaTRf     double\n",
       "history_ShAdDaTRft    double\n",
       "history_ShAdDaTRr     double\n",
       "history_ShAdDaTTRf    double\n",
       "history_ShAdDaTfF     double\n",
       "history_ShAdDaTfR     double\n",
       "history_ShAdDaTfRr    double\n",
       "history_ShAdDaTfr     double\n",
       "history_ShAdDaf       double\n",
       "history_ShAdDafF      double\n",
       "history_ShAdDafFR     double\n",
       "history_ShAdDafFr     double\n",
       "history_ShAdDafFrR    double\n",
       "history_ShAdDafFrr    double\n",
       "history_ShAdDafR      double\n",
       "history_ShAdDafr      double\n",
       "history_ShAdDafrFr    double\n",
       "history_ShAdDafrR     double\n",
       "history_ShAdDaft      double\n",
       "history_ShAdDaftF     double\n",
       "history_ShAdDaftFR    double\n",
       "history_ShAdDar       double\n",
       "history_ShAdDarfR     double\n",
       "history_ShAdDarr      double\n",
       "history_ShAdDatFf     double\n",
       "history_ShAdDatFr     double\n",
       "history_ShAdDatFrR    double\n",
       "history_ShAdDatR      double\n",
       "history_ShAdDatRRR    double\n",
       "history_ShAdDatf      double\n",
       "history_ShAdDatfF     double\n",
       "history_ShAdDatfr     double\n",
       "history_ShAdDatrfR    double\n",
       "history_ShAdDfFa      double\n",
       "history_ShAdDfFr      double\n",
       "history_ShAdDfr       double\n",
       "history_ShAdDr        double\n",
       "history_ShAdDtaFf     double\n",
       "history_ShAdDtaFr     double\n",
       "history_ShAdDtaR      double\n",
       "history_ShAdDtafF     double\n",
       "history_ShAdDtafFr    double\n",
       "history_ShAdF         double\n",
       "history_ShAdFaRf      double\n",
       "history_ShAdFaf       double\n",
       "history_ShAdaDR       double\n",
       "history_ShAdaFr       double\n",
       "history_ShAdfDF       double\n",
       "history_ShAdfDFr      double\n",
       "history_ShAdfDr       double\n",
       "history_ShAdfF        double\n",
       "history_ShAdfFa       double\n",
       "history_ShAdfr        double\n",
       "history_ShAdr         double\n",
       "history_ShAdtDaFr     double\n",
       "history_ShAdtDaFrR    double\n",
       "history_ShAdtDafF     double\n",
       "history_ShAdtfFa      double\n",
       "history_ShAfF         double\n",
       "history_ShAfFa        double\n",
       "history_ShAfFr        double\n",
       "history_ShAfdtDFr     double\n",
       "history_ShAfdtDr      double\n",
       "history_ShAfdtF       double\n",
       "history_ShAfdtFa      double\n",
       "history_ShAfr         double\n",
       "history_ShAr          double\n",
       "history_ShArR         double\n",
       "history_ShArr         double\n",
       "history_ShDadAf       double\n",
       "history_ShR           double\n",
       "history_ShrA          double\n",
       "history_ShwA          double\n",
       "history_ShwAr         double\n",
       "history_Sr            double\n",
       "history_^aA           double\n",
       "history_^aR           double\n",
       "history_^c            double\n",
       "history_^d            double\n",
       "history_^dDA          double\n",
       "history_^dtt          double\n",
       "history_^hA           double\n",
       "history_^hADFr        double\n",
       "history_^hADadfR      double\n",
       "history_^hADafF       double\n",
       "history_^hADr         double\n",
       "history_^hR           double\n",
       "history_^r            double\n",
       "history_nan           double"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "Out of memory allocating 124,156,416 bytes (allocated so far: 0 bytes).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Iterar sobre los chunks del array\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m array\u001b[38;5;241m.\u001b[39mto_delayed()\u001b[38;5;241m.\u001b[39mflatten():\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Convertir el chunk a un array de CuPy\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Realizar la PCA en el chunk\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     u, s, vh \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msvd(chunk, full_matrices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\victo\\anaconda3\\envs\\gpu-dask\\lib\\site-packages\\cupy\\_creation\\from_data.py:88\u001b[0m, in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, blocking)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21masarray\u001b[39m(a, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     57\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Converts an object to array.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03m    This is equivalent to ``array(a, dtype, copy=False, order=order)``.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m \n\u001b[0;32m     87\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_core\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mcupy\\_core\\core.pyx:2379\u001b[0m, in \u001b[0;36mcupy._core.core.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\_core\\core.pyx:2406\u001b[0m, in \u001b[0;36mcupy._core.core.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\_core\\core.pyx:2548\u001b[0m, in \u001b[0;36mcupy._core.core._array_default\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\_core\\core.pyx:132\u001b[0m, in \u001b[0;36mcupy._core.core.ndarray.__new__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\_core\\core.pyx:220\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_base._init\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\cuda\\memory.pyx:738\u001b[0m, in \u001b[0;36mcupy.cuda.memory.alloc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\cuda\\memory.pyx:1424\u001b[0m, in \u001b[0;36mcupy.cuda.memory.MemoryPool.malloc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\cuda\\memory.pyx:1445\u001b[0m, in \u001b[0;36mcupy.cuda.memory.MemoryPool.malloc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\cuda\\memory.pyx:1116\u001b[0m, in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool.malloc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\cuda\\memory.pyx:1137\u001b[0m, in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool._malloc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\cuda\\memory.pyx:1382\u001b[0m, in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool._try_malloc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\cuda\\memory.pyx:1385\u001b[0m, in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool._try_malloc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: Out of memory allocating 124,156,416 bytes (allocated so far: 0 bytes)."
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    df = dask.dataframe.read_csv(file_path_w11, assume_missing=True)\n",
    "    \n",
    "df = df.drop('6', axis=1)\n",
    "\n",
    "# Convertir todas las columnas a numéricas\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(pd.to_numeric, errors='coerce',  meta=(col, 'float64'))\n",
    "\n",
    "# Rellenar los valores NaN con 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Convertir el DataFrame de Dask a un array de Dask\n",
    "array = df.to_dask_array(lengths=True)\n",
    "\n",
    "# Inicializar una lista para almacenar los nombres de los archivos temporales\n",
    "temp_files = []\n",
    "\n",
    "# Iterar sobre los chunks del array\n",
    "for chunk in array.to_delayed().flatten():\n",
    "    # Convertir el chunk a un array de CuPy\n",
    "    chunk = cp.asarray(chunk.compute())\n",
    "    \n",
    "    # Realizar la PCA en el chunk\n",
    "    u, s, vh = cp.linalg.svd(chunk, full_matrices=False)\n",
    "    \n",
    "    #liberacion de memoria\n",
    "    cp._default_memory_pool.free_all_blocks()\n",
    "    \n",
    "    # Convertir los arrays a numpy\n",
    "    u = u.get()\n",
    "    s = s.get()\n",
    "    vh = vh.get()\n",
    "\n",
    "    \n",
    "    # Crear un archivo temporal para guardar los resultados de PCA\n",
    "    temp_file = tempfile.NamedTemporaryFile(dir=r\"D:\\Cursos\\REPOSITORIOS\\DATASET\\malware_total\\original\\dir\",delete=False)\n",
    "    \n",
    "     # Cerrar el archivo temporal antes de guardar los datos en él\n",
    "    temp_file.close()\n",
    "    \n",
    "     # Guardar los resultados de PCA en el archivo temporal\n",
    "    np.savez(temp_file.name, u=u, s=s, vh=vh)\n",
    "    \n",
    "    #Añadir el nombre del archivo temporal a la lista\n",
    "    temp_files.append(temp_file.name)\n",
    "    \n",
    "    # Liberar memoria de la GPU\n",
    "    cp._default_memory_pool.free_all_blocks()\n",
    "\n",
    "# Inicializar una lista para almacenar los resultados de PCA\n",
    "pca_results = []\n",
    "\n",
    "# Cargar los resultados de PCA de los archivos temporales\n",
    "for temp_file in temp_files:\n",
    "    try:\n",
    "        with np.load(temp_file) as data:\n",
    "            u = data['u']\n",
    "            s = data['s']\n",
    "            vh = data['vh']\n",
    "            pca_results.append((u, s, vh))\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo cargar el archivo {temp_file} debido al error: {e}\")\n",
    "    \n",
    "    # Intentar eliminar el archivo temporal\n",
    "    try:\n",
    "        os.remove(temp_file)\n",
    "    except PermissionError:\n",
    "        print(f\"No se pudo eliminar el archivo {temp_file}. Continuando con el siguiente archivo.\")\n",
    "        \n",
    "# Convertir la lista de resultados de PCA a un array de Dask respaldado por CuPy\n",
    "pca_results = da.from_array(cp.asarray(pca_results), chunks=(500, 500))\n",
    "\n",
    "# Realizar una operación de reducción en paralelo en la GPU\n",
    "pca_combined = pca_results.sum().compute()\n",
    "\n",
    "# Obtener las características (X) excluyendo la columna de la etiqueta\n",
    "X = pca_combined[:, :-1]\n",
    "\n",
    "# Obtener la etiqueta (y) que es la última columna\n",
    "y = pca_combined[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dask.dataframe.read_csv(file_path_w11, assume_missing=True, blocksize=1_000_000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"6\"])\n",
    "y = df[\"6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100, svd_solver='randomized')\n",
    "X_pca = pca.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza el split en conjunto de entrenamiento y conjunto de pruebas utilizando train_test_split de sklearn:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dask.dataframe.read_csv(file_path_w11, assume_missing=True, blocksize=None)\n",
    "\n",
    "# Ajustar el número de componentes a conservar en PCA\n",
    "n_components = 140\n",
    "\n",
    "# Realizar PCA\n",
    "pca = PCA(n_components=n_components, svd_solver='randomized', random_state=0)\n",
    "X = df.drop(columns=[df.columns[6]])\n",
    "Y = df[df.columns[6]].astype(np.float32)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Generar conjuntos de datos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "df.to_csv(\"D:\\Cursos\\REPOSITORIOS\\DATASET\\malware_total\\original\\PCA_df_one_hot_full_ml_mm.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-dask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
